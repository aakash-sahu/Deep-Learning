{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:44.125979Z",
     "iopub.status.busy": "2020-09-28T00:47:44.125242Z",
     "iopub.status.idle": "2020-09-28T00:47:44.128130Z",
     "shell.execute_reply": "2020-09-28T00:47:44.127676Z"
    },
    "papermill": {
     "duration": 0.033579,
     "end_time": "2020-09-28T00:47:44.128223",
     "exception": false,
     "start_time": "2020-09-28T00:47:44.094644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "## Comes preinstalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:44.185110Z",
     "iopub.status.busy": "2020-09-28T00:47:44.184412Z",
     "iopub.status.idle": "2020-09-28T00:47:44.186915Z",
     "shell.execute_reply": "2020-09-28T00:47:44.187422Z"
    },
    "papermill": {
     "duration": 0.031973,
     "end_time": "2020-09-28T00:47:44.187520",
     "exception": false,
     "start_time": "2020-09-28T00:47:44.155547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "#         pass\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:44.241852Z",
     "iopub.status.busy": "2020-09-28T00:47:44.241356Z",
     "iopub.status.idle": "2020-09-28T00:47:51.769840Z",
     "shell.execute_reply": "2020-09-28T00:47:51.770738Z"
    },
    "papermill": {
     "duration": 7.557958,
     "end_time": "2020-09-28T00:47:51.770938",
     "exception": false,
     "start_time": "2020-09-28T00:47:44.212980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "##Use pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043038,
     "end_time": "2020-09-28T00:47:51.857748",
     "exception": false,
     "start_time": "2020-09-28T00:47:51.814710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sentiment Analysis classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:51.948675Z",
     "iopub.status.busy": "2020-09-28T00:47:51.947883Z",
     "iopub.status.idle": "2020-09-28T00:47:51.950204Z",
     "shell.execute_reply": "2020-09-28T00:47:51.950655Z"
    },
    "papermill": {
     "duration": 0.049802,
     "end_time": "2020-09-28T00:47:51.950759",
     "exception": false,
     "start_time": "2020-09-28T00:47:51.900957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nlp_sentence_sentiment = pipeline('sentiment-analysis')\n",
    "# print(nlp_sentence_sentiment(\"It's a bad coffee!!\"))\n",
    "# print(nlp_sentence_sentiment(\"It's a good coffee!!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046415,
     "end_time": "2020-09-28T00:47:52.050946",
     "exception": false,
     "start_time": "2020-09-28T00:47:52.004531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Token Classification - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:52.147995Z",
     "iopub.status.busy": "2020-09-28T00:47:52.147191Z",
     "iopub.status.idle": "2020-09-28T00:47:52.149309Z",
     "shell.execute_reply": "2020-09-28T00:47:52.148666Z"
    },
    "papermill": {
     "duration": 0.055074,
     "end_time": "2020-09-28T00:47:52.149419",
     "exception": false,
     "start_time": "2020-09-28T00:47:52.094345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nlp_token_class = pipeline('ner')\n",
    "# nlp_token_class('Hugging Face is a French company based in New-York.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041848,
     "end_time": "2020-09-28T00:47:52.230836",
     "exception": false,
     "start_time": "2020-09-28T00:47:52.188988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Remaninig in pipeline...\n",
    "https://github.com/huggingface/transformers/blob/master/notebooks/03-pipelines.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026394,
     "end_time": "2020-09-28T00:47:52.289250",
     "exception": false,
     "start_time": "2020-09-28T00:47:52.262856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Topic Extraction using Sem Eval 2010 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:52.384737Z",
     "iopub.status.busy": "2020-09-28T00:47:52.384055Z",
     "iopub.status.idle": "2020-09-28T00:47:53.089041Z",
     "shell.execute_reply": "2020-09-28T00:47:53.089458Z"
    },
    "papermill": {
     "duration": 0.763477,
     "end_time": "2020-09-28T00:47:53.089588",
     "exception": false,
     "start_time": "2020-09-28T00:47:52.326111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-41.key\r\n",
      "C-41.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/semeval-2010topic-extraction/maui-semeval2010-train | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:53.151823Z",
     "iopub.status.busy": "2020-09-28T00:47:53.151203Z",
     "iopub.status.idle": "2020-09-28T00:47:53.825779Z",
     "shell.execute_reply": "2020-09-28T00:47:53.826232Z"
    },
    "papermill": {
     "duration": 0.708841,
     "end_time": "2020-09-28T00:47:53.826359",
     "exception": false,
     "start_time": "2020-09-28T00:47:53.117518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['C-41.txt', 'C-42.txt', 'C-44.txt'], ['C-41.key', 'C-42.key', 'C-44.key'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "train_path = \"/kaggle/input/semeval-2010topic-extraction/maui-semeval2010-train\"\n",
    "\n",
    "txt = sorted([f for f in os.listdir(train_path) if not f.endswith(\"-justTitle.txt\") and not f.endswith(\".key\") and not f.endswith(\"-CrowdCountskey\")])\n",
    "key = sorted([f for f in os.listdir(train_path) if f.endswith(\".key\")])\n",
    "\n",
    "txt[:3], key[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:53.886063Z",
     "iopub.status.busy": "2020-09-28T00:47:53.885499Z",
     "iopub.status.idle": "2020-09-28T00:47:53.889139Z",
     "shell.execute_reply": "2020-09-28T00:47:53.889514Z"
    },
    "papermill": {
     "duration": 0.035582,
     "end_time": "2020-09-28T00:47:53.889627",
     "exception": false,
     "start_time": "2020-09-28T00:47:53.854045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filekey = dict()\n",
    "for i, k in enumerate(txt):\n",
    "    filekey[key[i]] = k\n",
    "    \n",
    "# filekey\n",
    "# {'C-41.key': 'C-41.txt',\n",
    "#  'C-42.key': 'C-42.txt',\n",
    "#  'C-44.key': 'C-44.txt',...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:53.961213Z",
     "iopub.status.busy": "2020-09-28T00:47:53.957846Z",
     "iopub.status.idle": "2020-09-28T00:47:53.963838Z",
     "shell.execute_reply": "2020-09-28T00:47:53.963424Z"
    },
    "papermill": {
     "duration": 0.046469,
     "end_time": "2020-09-28T00:47:53.963941",
     "exception": false,
     "start_time": "2020-09-28T00:47:53.917472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(key):\n",
    "    sentences = \"\"\n",
    "    file_path = os.path.join(train_path, filekey[key])\n",
    "#     print(file_path)\n",
    "    for line in open(file_path, 'r', encoding=\"utf8\"):\n",
    "        sentences += (\" \" + line.rstrip())\n",
    "    tokens = sent_tokenize(sentences)\n",
    "    key_file = open(os.path.join(train_path, str(key)),'r')\n",
    "    keys = [line.strip() for line in key_file]\n",
    "    key_sent = []\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        z = ['O'] * len(token.split())\n",
    "        for k in keys:\n",
    "            if k in token:\n",
    "                \n",
    "                if len(k.split())==1:\n",
    "                    try:\n",
    "                        z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                elif len(k.split())>1:\n",
    "                    try:\n",
    "                        if token.lower().split().index(k.lower().split()[0]) and token.lower().split().index(k.lower().split()[-1]):\n",
    "                            z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
    "                            for j in range(1, len(k.split())):\n",
    "                                z[token.lower().split().index(k.lower().split()[j])] = 'I'\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "        for m, n in enumerate(z):\n",
    "            if z[m] == 'I' and z[m-1] == 'O':\n",
    "                z[m] = 'O'\n",
    "\n",
    "        if set(z) != {'O'}:\n",
    "            labels.append(z) \n",
    "            key_sent.append(token)\n",
    "    return key_sent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:54.025114Z",
     "iopub.status.busy": "2020-09-28T00:47:54.024307Z",
     "iopub.status.idle": "2020-09-28T00:47:58.171707Z",
     "shell.execute_reply": "2020-09-28T00:47:58.170620Z"
    },
    "papermill": {
     "duration": 4.180352,
     "end_time": "2020-09-28T00:47:58.171832",
     "exception": false,
     "start_time": "2020-09-28T00:47:53.991480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_ = []\n",
    "labels_ = []\n",
    "for key, value in filekey.items():\n",
    "    s, l = convert(key)\n",
    "    sentences_.append(s)\n",
    "    labels_.append(l)\n",
    "sentences = [item for sublist in sentences_ for item in sublist]\n",
    "labels = [item for sublist in labels_ for item in sublist]\n",
    "# print(len(sentences), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.235518Z",
     "iopub.status.busy": "2020-09-28T00:47:58.234646Z",
     "iopub.status.idle": "2020-09-28T00:47:58.237448Z",
     "shell.execute_reply": "2020-09-28T00:47:58.236024Z"
    },
    "papermill": {
     "duration": 0.037797,
     "end_time": "2020-09-28T00:47:58.237547",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.199750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8584 8584\n",
      "12 12\n",
      "Overall, HyARM ensures efficient, predictable, and adaptive resource management for DRE systems. ['O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences), len(labels))\n",
    "check_idx = 10\n",
    "print(len(sentences[check_idx].split()), len(labels[check_idx]))\n",
    "print(sentences[check_idx], labels[check_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027836,
     "end_time": "2020-09-28T00:47:58.293535",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.265699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.356037Z",
     "iopub.status.busy": "2020-09-28T00:47:58.355397Z",
     "iopub.status.idle": "2020-09-28T00:47:58.408735Z",
     "shell.execute_reply": "2020-09-28T00:47:58.408327Z"
    },
    "papermill": {
     "duration": 0.086806,
     "end_time": "2020-09-28T00:47:58.408821",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.322015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification #, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.469696Z",
     "iopub.status.busy": "2020-09-28T00:47:58.468438Z",
     "iopub.status.idle": "2020-09-28T00:47:58.471126Z",
     "shell.execute_reply": "2020-09-28T00:47:58.471572Z"
    },
    "papermill": {
     "duration": 0.034643,
     "end_time": "2020-09-28T00:47:58.471674",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.437031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "\n",
    "#batch size\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.531701Z",
     "iopub.status.busy": "2020-09-28T00:47:58.531201Z",
     "iopub.status.idle": "2020-09-28T00:47:58.535127Z",
     "shell.execute_reply": "2020-09-28T00:47:58.534710Z"
    },
    "papermill": {
     "duration": 0.035605,
     "end_time": "2020-09-28T00:47:58.535212",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.499607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag2idx = {'B': 0, 'I': 1, 'O': 2}\n",
    "tags_vals = ['B', 'I', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.919848Z",
     "iopub.status.busy": "2020-09-28T00:47:58.919271Z",
     "iopub.status.idle": "2020-09-28T00:47:58.925096Z",
     "shell.execute_reply": "2020-09-28T00:47:58.923965Z"
    },
    "papermill": {
     "duration": 0.361712,
     "end_time": "2020-09-28T00:47:58.925238",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.563526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(device, n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:47:58.988996Z",
     "iopub.status.busy": "2020-09-28T00:47:58.988194Z",
     "iopub.status.idle": "2020-09-28T00:48:01.679772Z",
     "shell.execute_reply": "2020-09-28T00:48:01.680188Z"
    },
    "papermill": {
     "duration": 2.725189,
     "end_time": "2020-09-28T00:48:01.680318",
     "exception": false,
     "start_time": "2020-09-28T00:47:58.955129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cee967429534c2fbc4a0f3c9a061667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:01.763713Z",
     "iopub.status.busy": "2020-09-28T00:48:01.753401Z",
     "iopub.status.idle": "2020-09-28T00:48:07.919941Z",
     "shell.execute_reply": "2020-09-28T00:48:07.918694Z"
    },
    "papermill": {
     "duration": 6.209441,
     "end_time": "2020-09-28T00:48:07.920058",
     "exception": false,
     "start_time": "2020-09-28T00:48:01.710617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:07.986511Z",
     "iopub.status.busy": "2020-09-28T00:48:07.985281Z",
     "iopub.status.idle": "2020-09-28T00:48:07.988933Z",
     "shell.execute_reply": "2020-09-28T00:48:07.988283Z"
    },
    "papermill": {
     "duration": 0.038735,
     "end_time": "2020-09-28T00:48:07.989052",
     "exception": false,
     "start_time": "2020-09-28T00:48:07.950317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['overall', ',', 'h', '##yar', '##m', 'ensures', 'efficient', ',', 'predictable', ',', 'and', 'adaptive', 'resource', 'management', 'for', 'dr', '##e', 'systems', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_texts[check_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:08.068014Z",
     "iopub.status.busy": "2020-09-28T00:48:08.062814Z",
     "iopub.status.idle": "2020-09-28T00:48:08.620838Z",
     "shell.execute_reply": "2020-09-28T00:48:08.620362Z"
    },
    "papermill": {
     "duration": 0.600795,
     "end_time": "2020-09-28T00:48:08.620987",
     "exception": false,
     "start_time": "2020-09-28T00:48:08.020192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:08.690467Z",
     "iopub.status.busy": "2020-09-28T00:48:08.689798Z",
     "iopub.status.idle": "2020-09-28T00:48:08.696037Z",
     "shell.execute_reply": "2020-09-28T00:48:08.696602Z"
    },
    "papermill": {
     "duration": 0.044584,
     "end_time": "2020-09-28T00:48:08.696718",
     "exception": false,
     "start_time": "2020-09-28T00:48:08.652134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3452, 1010, 1044, 13380]\n",
      "(8584, 75) (8584, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3452,  1010,  1044, 13380,  2213, 21312,  8114,  1010, 21425,\n",
       "        1010,  1998, 19293,  7692,  2968,  2005,  2852,  2063,  3001,\n",
       "        1012,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_ids(tokenized_texts[check_idx])[:4])\n",
    "print(input_ids.shape,tags.shape)\n",
    "input_ids[check_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:08.785567Z",
     "iopub.status.busy": "2020-09-28T00:48:08.780418Z",
     "iopub.status.idle": "2020-09-28T00:48:09.387854Z",
     "shell.execute_reply": "2020-09-28T00:48:09.386833Z"
    },
    "papermill": {
     "duration": 0.654578,
     "end_time": "2020-09-28T00:48:09.388006",
     "exception": false,
     "start_time": "2020-09-28T00:48:08.733428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:09.455223Z",
     "iopub.status.busy": "2020-09-28T00:48:09.454360Z",
     "iopub.status.idle": "2020-09-28T00:48:09.458733Z",
     "shell.execute_reply": "2020-09-28T00:48:09.459472Z"
    },
    "papermill": {
     "duration": 0.039937,
     "end_time": "2020-09-28T00:48:09.459615",
     "exception": false,
     "start_time": "2020-09-28T00:48:09.419678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8584 [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(len(attention_masks), attention_masks[check_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:09.529169Z",
     "iopub.status.busy": "2020-09-28T00:48:09.528303Z",
     "iopub.status.idle": "2020-09-28T00:48:09.542727Z",
     "shell.execute_reply": "2020-09-28T00:48:09.543274Z"
    },
    "papermill": {
     "duration": 0.051944,
     "end_time": "2020-09-28T00:48:09.543399",
     "exception": false,
     "start_time": "2020-09-28T00:48:09.491455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:09.615876Z",
     "iopub.status.busy": "2020-09-28T00:48:09.615211Z",
     "iopub.status.idle": "2020-09-28T00:48:09.692211Z",
     "shell.execute_reply": "2020-09-28T00:48:09.691679Z"
    },
    "papermill": {
     "duration": 0.117492,
     "end_time": "2020-09-28T00:48:09.692330",
     "exception": false,
     "start_time": "2020-09-28T00:48:09.574838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:09.764296Z",
     "iopub.status.busy": "2020-09-28T00:48:09.763497Z",
     "iopub.status.idle": "2020-09-28T00:48:09.766387Z",
     "shell.execute_reply": "2020-09-28T00:48:09.765984Z"
    },
    "papermill": {
     "duration": 0.041542,
     "end_time": "2020-09-28T00:48:09.766476",
     "exception": false,
     "start_time": "2020-09-28T00:48:09.724934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:09.840076Z",
     "iopub.status.busy": "2020-09-28T00:48:09.839337Z",
     "iopub.status.idle": "2020-09-28T00:48:56.001477Z",
     "shell.execute_reply": "2020-09-28T00:48:56.000966Z"
    },
    "papermill": {
     "duration": 46.19932,
     "end_time": "2020-09-28T00:48:56.001591",
     "exception": false,
     "start_time": "2020-09-28T00:48:09.802271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3839a6610d4ca0b547a29d59e319c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edc66eb744346e0b8d7303b694a1c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:56.076640Z",
     "iopub.status.busy": "2020-09-28T00:48:56.075688Z",
     "iopub.status.idle": "2020-09-28T00:48:56.079530Z",
     "shell.execute_reply": "2020-09-28T00:48:56.079962Z"
    },
    "papermill": {
     "duration": 0.044373,
     "end_time": "2020-09-28T00:48:56.080065",
     "exception": false,
     "start_time": "2020-09-28T00:48:56.035692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:48:56.157791Z",
     "iopub.status.busy": "2020-09-28T00:48:56.157134Z",
     "iopub.status.idle": "2020-09-28T00:49:02.443659Z",
     "shell.execute_reply": "2020-09-28T00:49:02.443184Z"
    },
    "papermill": {
     "duration": 6.328847,
     "end_time": "2020-09-28T00:49:02.443765",
     "exception": false,
     "start_time": "2020-09-28T00:48:56.114918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  GPU\n"
     ]
    }
   ],
   "source": [
    "if device.type ==\"cuda\":\n",
    "    print(\"Using  GPU\")\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    print(\"Using CPU. Switch to GPU or TPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:02.520921Z",
     "iopub.status.busy": "2020-09-28T00:49:02.520296Z",
     "iopub.status.idle": "2020-09-28T00:49:02.615671Z",
     "shell.execute_reply": "2020-09-28T00:49:02.615209Z"
    },
    "papermill": {
     "duration": 0.136503,
     "end_time": "2020-09-28T00:49:02.615775",
     "exception": false,
     "start_time": "2020-09-28T00:49:02.479272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('classifier.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0082,  0.0015, -0.0111,  ...,  0.0227, -0.0138, -0.0153],\n",
       "          [ 0.0230,  0.0254, -0.0039,  ...,  0.0021, -0.0066, -0.0129],\n",
       "          [ 0.0066, -0.0075,  0.0006,  ...,  0.0042, -0.0117,  0.0040]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('classifier.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0.], device='cuda:0', requires_grad=True))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:02.696337Z",
     "iopub.status.busy": "2020-09-28T00:49:02.695618Z",
     "iopub.status.idle": "2020-09-28T00:49:02.698502Z",
     "shell.execute_reply": "2020-09-28T00:49:02.698083Z"
    },
    "papermill": {
     "duration": 0.047145,
     "end_time": "2020-09-28T00:49:02.698594",
     "exception": false,
     "start_time": "2020-09-28T00:49:02.651449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:02.776704Z",
     "iopub.status.busy": "2020-09-28T00:49:02.775717Z",
     "iopub.status.idle": "2020-09-28T00:49:02.781442Z",
     "shell.execute_reply": "2020-09-28T00:49:02.781833Z"
    },
    "papermill": {
     "duration": 0.048313,
     "end_time": "2020-09-28T00:49:02.781968",
     "exception": false,
     "start_time": "2020-09-28T00:49:02.733655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0\n",
       "    weight_decay_rate: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 3e-05\n",
       "    weight_decay: 0\n",
       "    weight_decay_rate: 0.0\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len([x for x in model.named_parameters()]))\n",
    "print(len(optimizer_grouped_parameters))\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:02.859375Z",
     "iopub.status.busy": "2020-09-28T00:49:02.858586Z",
     "iopub.status.idle": "2020-09-28T00:49:02.862249Z",
     "shell.execute_reply": "2020-09-28T00:49:02.861791Z"
    },
    "papermill": {
     "duration": 0.04435,
     "end_time": "2020-09-28T00:49:02.862338",
     "exception": false,
     "start_time": "2020-09-28T00:49:02.817988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:02.956340Z",
     "iopub.status.busy": "2020-09-28T00:49:02.955538Z",
     "iopub.status.idle": "2020-09-28T00:49:59.198420Z",
     "shell.execute_reply": "2020-09-28T00:49:59.197846Z"
    },
    "papermill": {
     "duration": 56.299253,
     "end_time": "2020-09-28T00:49:59.198540",
     "exception": false,
     "start_time": "2020-09-28T00:49:02.899287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval[gpu]\r\n",
      "  Downloading seqeval-0.0.12.tar.gz (21 kB)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval[gpu]) (1.18.5)\r\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.7/site-packages (from seqeval[gpu]) (2.4.3)\r\n",
      "Collecting tensorflow-gpu\r\n",
      "  Downloading tensorflow_gpu-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 23 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval[gpu]) (5.3.1)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.4.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.10.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.1.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.2.0)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.6.3)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.10.0)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.32.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (3.3.0)\r\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (2.3.0)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.3.3)\r\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.1.2)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (3.13.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (2.3.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.11.2)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.34.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (2.23.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (0.4.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (3.2.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (1.7.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (1.0.1)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (4.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (3.1.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (0.2.7)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (2.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (1.24.3)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (3.0.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu->seqeval[gpu]) (3.0.1)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=83903c1de8c85a625e5b8218fc005779ced42584a5a819e7b5cbacbf0cd0655a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: tensorflow-gpu, seqeval\r\n",
      "Successfully installed seqeval-0.0.12 tensorflow-gpu-2.3.1\r\n"
     ]
    }
   ],
   "source": [
    "if device.type==\"cpu\":\n",
    "    !pip install seqeval[cpu]\n",
    "else:\n",
    "     !pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:49:59.665534Z",
     "iopub.status.busy": "2020-09-28T00:49:59.664717Z",
     "iopub.status.idle": "2020-09-28T00:49:59.670916Z",
     "shell.execute_reply": "2020-09-28T00:49:59.670483Z"
    },
    "papermill": {
     "duration": 0.242949,
     "end_time": "2020-09-28T00:49:59.671027",
     "exception": false,
     "start_time": "2020-09-28T00:49:59.428078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:50:00.132468Z",
     "iopub.status.busy": "2020-09-28T00:50:00.131451Z",
     "iopub.status.idle": "2020-09-28T00:54:37.207780Z",
     "shell.execute_reply": "2020-09-28T00:54:37.206658Z"
    },
    "papermill": {
     "duration": 277.312769,
     "end_time": "2020-09-28T00:54:37.207980",
     "exception": false,
     "start_time": "2020-09-28T00:49:59.895211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18749749426506768\n",
      "Validation loss: 0.14298865088710078\n",
      "Validation Accuracy: 0.9781235711019661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 1/4 [01:09<03:29, 69.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.28101644245142\n",
      "Train loss: 0.12792086533524774\n",
      "Validation loss: 0.11268970729024322\n",
      "Validation Accuracy: 0.9766489483310472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [02:18<02:18, 69.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.4045627376425855\n",
      "Train loss: 0.09281401614820169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 3/4 [03:27<01:09, 69.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.10265495462550057\n",
      "Validation Accuracy: 0.9701977594878831\n",
      "F1-Score: 0.41341795104261114\n",
      "Train loss: 0.07213048656925189\n",
      "Validation loss: 0.09901078293720882\n",
      "Validation Accuracy: 0.9695547553726565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [04:37<00:00, 69.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.42679037402145553\n",
      "CPU times: user 3min 9s, sys: 1min 24s, total: 4min 34s\n",
      "Wall time: 4min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            eval_outputs = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            tmp_eval_loss = eval_outputs[0]\n",
    "            logits = eval_outputs[1]\n",
    "#             logits = model(b_input_ids, token_type_ids=None,\n",
    "#                            attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:37.680595Z",
     "iopub.status.busy": "2020-09-28T00:54:37.679691Z",
     "iopub.status.idle": "2020-09-28T00:54:37.686875Z",
     "shell.execute_reply": "2020-09-28T00:54:37.687464Z"
    },
    "papermill": {
     "duration": 0.248635,
     "end_time": "2020-09-28T00:54:37.687583",
     "exception": false,
     "start_time": "2020-09-28T00:54:37.438948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64425 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pred_tags), len(pred_tags[0]))\n",
    "pred_tags[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:38.254779Z",
     "iopub.status.busy": "2020-09-28T00:54:38.247043Z",
     "iopub.status.idle": "2020-09-28T00:54:40.846311Z",
     "shell.execute_reply": "2020-09-28T00:54:40.845339Z"
    },
    "papermill": {
     "duration": 2.923861,
     "end_time": "2020-09-28T00:54:40.846417",
     "exception": false,
     "start_time": "2020-09-28T00:54:37.922556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.09901078293720882\n",
      "Validation Accuracy: 0.9695547553726565\n",
      "Validation F1-Score: 0.42679037402145553\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for batch in valid_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_eval_outputs = model(b_input_ids, token_type_ids=None,\n",
    "                              attention_mask=b_input_mask, labels=b_labels)\n",
    "        tmp_eval_loss = test_eval_outputs[0]\n",
    "        logits = test_eval_outputs[1]\n",
    "#         logits = model(b_input_ids, token_type_ids=None,\n",
    "#                        attention_mask=b_input_mask)\n",
    "        \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    true_labels.append(label_ids)\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    nb_eval_examples += b_input_ids.size(0)\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
    "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
    "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
    "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.25211,
     "end_time": "2020-09-28T00:54:41.339551",
     "exception": false,
     "start_time": "2020-09-28T00:54:41.087441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get keywords from sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:41.816910Z",
     "iopub.status.busy": "2020-09-28T00:54:41.816301Z",
     "iopub.status.idle": "2020-09-28T00:54:41.819741Z",
     "shell.execute_reply": "2020-09-28T00:54:41.818827Z"
    },
    "papermill": {
     "duration": 0.248682,
     "end_time": "2020-09-28T00:54:41.819840",
     "exception": false,
     "start_time": "2020-09-28T00:54:41.571158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keywordextract(sentence):\n",
    "    text = sentence\n",
    "    tkns = tokenizer.tokenize(text)\n",
    "#     print(len(tkns), tkns)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
    "    segments_ids = [0] * len(tkns)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    output = model(tokens_tensor, token_type_ids=None,\n",
    "                                  attention_mask=segments_tensors)\n",
    "    print(output)\n",
    "    logit = output[0]\n",
    "    logit = logit.detach().cpu().numpy()\n",
    "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
    "    print(prediction)\n",
    "    for k, j in enumerate(prediction[0]):\n",
    "        if j==1 or j==0:\n",
    "            print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:42.285612Z",
     "iopub.status.busy": "2020-09-28T00:54:42.283818Z",
     "iopub.status.idle": "2020-09-28T00:54:42.286265Z",
     "shell.execute_reply": "2020-09-28T00:54:42.286675Z"
    },
    "papermill": {
     "duration": 0.239327,
     "end_time": "2020-09-28T00:54:42.286786",
     "exception": false,
     "start_time": "2020-09-28T00:54:42.047459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"The solution is based upon an abstract representation of the mobile object system.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:42.791392Z",
     "iopub.status.busy": "2020-09-28T00:54:42.790597Z",
     "iopub.status.idle": "2020-09-28T00:54:42.825765Z",
     "shell.execute_reply": "2020-09-28T00:54:42.825258Z"
    },
    "papermill": {
     "duration": 0.270207,
     "end_time": "2020-09-28T00:54:42.825869",
     "exception": false,
     "start_time": "2020-09-28T00:54:42.555662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-1.6967, -3.2741,  4.5658],\n",
      "         [-0.3182, -3.0870,  3.0900],\n",
      "         [-2.4640, -3.0383,  4.9970],\n",
      "         [-2.3214, -3.0440,  4.9129],\n",
      "         [-2.5085, -2.9729,  5.0386],\n",
      "         [-2.3800, -3.0383,  4.9334],\n",
      "         [-0.7271, -3.0077,  3.1591],\n",
      "         [-0.3596, -1.9379,  1.8227],\n",
      "         [-2.5585, -2.8082,  4.9467],\n",
      "         [-1.6948, -3.2882,  4.6152],\n",
      "         [ 2.7192, -3.1014,  0.5581],\n",
      "         [-2.6877,  1.5002,  0.7933],\n",
      "         [-3.3463, -2.1863,  5.0999],\n",
      "         [-2.8180, -3.2575,  5.7694]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>),)\n",
      "[[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2]]\n",
      "mobile 0\n",
      "object 1\n"
     ]
    }
   ],
   "source": [
    "keywordextract(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:43.302953Z",
     "iopub.status.busy": "2020-09-28T00:54:43.302162Z",
     "iopub.status.idle": "2020-09-28T00:54:44.240097Z",
     "shell.execute_reply": "2020-09-28T00:54:44.239225Z"
    },
    "papermill": {
     "duration": 1.18069,
     "end_time": "2020-09-28T00:54:44.240211",
     "exception": false,
     "start_time": "2020-09-28T00:54:43.059521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bert_topic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:44.726985Z",
     "iopub.status.busy": "2020-09-28T00:54:44.703560Z",
     "iopub.status.idle": "2020-09-28T00:54:45.378939Z",
     "shell.execute_reply": "2020-09-28T00:54:45.378438Z"
    },
    "papermill": {
     "duration": 0.91012,
     "end_time": "2020-09-28T00:54:45.379051",
     "exception": false,
     "start_time": "2020-09-28T00:54:44.468931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3864\r\n",
      "---------- 1 root root 3947454 Sep 28 00:54 __notebook__.ipynb\r\n",
      "drwxr-xr-x 2 root root    4096 Sep 28 00:54 bert_topic_model\r\n",
      "drwxr-xr-x 2 root root    4096 Sep 28 00:47 wandb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:45.846164Z",
     "iopub.status.busy": "2020-09-28T00:54:45.845421Z",
     "iopub.status.idle": "2020-09-28T00:54:49.112685Z",
     "shell.execute_reply": "2020-09-28T00:54:49.113337Z"
    },
    "papermill": {
     "duration": 3.504276,
     "end_time": "2020-09-28T00:54:49.113513",
     "exception": false,
     "start_time": "2020-09-28T00:54:45.609237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "model2 = BertForTokenClassification.from_pretrained(\"bert_topic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:49.848560Z",
     "iopub.status.busy": "2020-09-28T00:54:49.847817Z",
     "iopub.status.idle": "2020-09-28T00:54:49.851404Z",
     "shell.execute_reply": "2020-09-28T00:54:49.850970Z"
    },
    "papermill": {
     "duration": 0.332136,
     "end_time": "2020-09-28T00:54:49.851503",
     "exception": false,
     "start_time": "2020-09-28T00:54:49.519367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keywordextract_saved(sentence, use_model):\n",
    "    text = sentence\n",
    "    tkns = tokenizer.tokenize(text)\n",
    "#     print(len(tkns), tkns)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
    "    segments_ids = [0] * len(tkns)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "    use_model.eval()\n",
    "    prediction = []\n",
    "    output = use_model(tokens_tensor, token_type_ids=None,\n",
    "                                  attention_mask=segments_tensors)\n",
    "    print(output)\n",
    "    logit = output[0]\n",
    "    logit = logit.detach().cpu().numpy()\n",
    "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
    "    print(prediction)\n",
    "    for k, j in enumerate(prediction[0]):\n",
    "        if j==1 or j==0:\n",
    "            print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-28T00:54:50.315285Z",
     "iopub.status.busy": "2020-09-28T00:54:50.314587Z",
     "iopub.status.idle": "2020-09-28T00:54:50.781754Z",
     "shell.execute_reply": "2020-09-28T00:54:50.783221Z"
    },
    "papermill": {
     "duration": 0.703862,
     "end_time": "2020-09-28T00:54:50.783421",
     "exception": false,
     "start_time": "2020-09-28T00:54:50.079559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-20ff2ca216c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywordextract_saved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-951cd1d66f6d>\u001b[0m in \u001b[0;36mkeywordextract_saved\u001b[0;34m(sentence, use_model)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     output = use_model(tokens_tensor, token_type_ids=None,\n\u001b[0;32m---> 12\u001b[0;31m                                   attention_mask=segments_tensors)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m         )\n\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "keywordextract_saved(text, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.229489,
     "end_time": "2020-09-28T00:54:51.382158",
     "exception": false,
     "start_time": "2020-09-28T00:54:51.152669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 431.924486,
   "end_time": "2020-09-28T00:54:52.221653",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-28T00:47:40.297167",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0453e948838b456aa53390ad527ac195": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a1212707c5c4266846d76ec43198708",
       "placeholder": "​",
       "style": "IPY_MODEL_3c6b3dd7f7dc49fea08d5c5a9bf55d31",
       "value": " 440M/440M [00:38&lt;00:00, 11.3MB/s]"
      }
     },
     "1ca8565fd80c432e8e7bdfe8426d21b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2b72e2bd4c534d2eb3c6acb682deb067": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3353fea174a7489ba04dee9ba0f0e4fb",
       "placeholder": "​",
       "style": "IPY_MODEL_64c8558c23f04daabf65366deca7ddd2",
       "value": " 433/433 [00:41&lt;00:00, 10.5B/s]"
      }
     },
     "2c0459dcea7f4b2a843e98382a8a7c02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bfc149bd489a4e8c8551aab4acd7076a",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c75ad984889f42608734752a5aecefad",
       "value": 231508.0
      }
     },
     "3353fea174a7489ba04dee9ba0f0e4fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c6b3dd7f7dc49fea08d5c5a9bf55d31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c3839a6610d4ca0b547a29d59e319c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9b8043c1bf0b4a5a9cee65023f5b80da",
        "IPY_MODEL_2b72e2bd4c534d2eb3c6acb682deb067"
       ],
       "layout": "IPY_MODEL_e0fd2144c26543e1bd9d39a619e473a9"
      }
     },
     "55515091ec364bf4af52d38a81e811cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b382484b1a1b4474ae53c85c65b39fcd",
       "placeholder": "​",
       "style": "IPY_MODEL_6f6ea8dab51746779c7eea636b570c98",
       "value": " 232k/232k [00:00&lt;00:00, 322kB/s]"
      }
     },
     "5cee967429534c2fbc4a0f3c9a061667": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c0459dcea7f4b2a843e98382a8a7c02",
        "IPY_MODEL_55515091ec364bf4af52d38a81e811cc"
       ],
       "layout": "IPY_MODEL_899ab79ecc5e45c99caf726c4ddc64fb"
      }
     },
     "64c8558c23f04daabf65366deca7ddd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f6ea8dab51746779c7eea636b570c98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7edc66eb744346e0b8d7303b694a1c80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_87746db8d0ce4b49acb0399583bef42c",
        "IPY_MODEL_0453e948838b456aa53390ad527ac195"
       ],
       "layout": "IPY_MODEL_a9c1313eb1fd4677809668e88cecb66d"
      }
     },
     "87746db8d0ce4b49acb0399583bef42c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f08554ade9bc424084e32d26fb9591b9",
       "max": 440473133.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ca8565fd80c432e8e7bdfe8426d21b5",
       "value": 440473133.0
      }
     },
     "899ab79ecc5e45c99caf726c4ddc64fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a1212707c5c4266846d76ec43198708": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b8043c1bf0b4a5a9cee65023f5b80da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4223551ff3e473393ee87b2a9733dc6",
       "max": 433.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7ee635fabd6427695f4aafdf036a9ab",
       "value": 433.0
      }
     },
     "a9c1313eb1fd4677809668e88cecb66d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b382484b1a1b4474ae53c85c65b39fcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfc149bd489a4e8c8551aab4acd7076a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c75ad984889f42608734752a5aecefad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e0fd2144c26543e1bd9d39a619e473a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f08554ade9bc424084e32d26fb9591b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4223551ff3e473393ee87b2a9733dc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7ee635fabd6427695f4aafdf036a9ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
